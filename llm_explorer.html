<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>AI Model Explorer</title>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            background: #f5f7fa;
            min-height: 100vh;
            padding: 20px;
            color: #2d3748;
        }

        .container {
            max-width: 1400px;
            margin: 0 auto;
        }

        header {
            text-align: center;
            margin-bottom: 30px;
        }

        h1 {
            font-size: 2.5em;
            margin-bottom: 10px;
            color: #1a202c;
        }

        .subtitle {
            font-size: 1.1em;
            color: #4a5568;
        }

        .tabs {
            display: flex;
            gap: 8px;
            margin-bottom: 20px;
            border-bottom: 2px solid #e2e8f0;
            background: white;
            padding: 0 20px;
            border-radius: 8px 8px 0 0;
        }

        .tab {
            padding: 15px 25px;
            background: none;
            border: none;
            cursor: pointer;
            font-size: 1em;
            color: #718096;
            transition: all 0.3s;
            border-bottom: 3px solid transparent;
            margin-bottom: -2px;
        }

        .tab:hover {
            color: #2d3748;
        }

        .tab.active {
            color: #2d3748;
            border-bottom-color: #4a5568;
            font-weight: 600;
        }

        .tab-content {
            display: none;
        }

        .tab-content.active {
            display: block;
        }

        .controls {
            background: white;
            border-radius: 8px;
            padding: 20px;
            margin-bottom: 20px;
            box-shadow: 0 1px 3px rgba(0,0,0,0.1);
        }

        .filter-group {
            margin-bottom: 15px;
        }

        .filter-group:last-child {
            margin-bottom: 0;
        }

        .filter-group label {
            display: block;
            font-weight: 600;
            margin-bottom: 8px;
            color: #2d3748;
        }

        .filter-buttons {
            display: flex;
            flex-wrap: wrap;
            gap: 8px;
        }

        .filter-btn {
            padding: 8px 16px;
            border: 2px solid #cbd5e0;
            background: white;
            color: #4a5568;
            border-radius: 6px;
            cursor: pointer;
            transition: all 0.2s;
            font-size: 0.9em;
        }

        .filter-btn:hover {
            border-color: #4a5568;
            color: #2d3748;
        }

        .filter-btn.active {
            background: #4a5568;
            color: white;
            border-color: #4a5568;
        }

        .models-grid {
            display: grid;
            grid-template-columns: repeat(auto-fill, minmax(320px, 1fr));
            gap: 20px;
            margin-bottom: 30px;
        }

        .model-card {
            background: white;
            border-radius: 8px;
            padding: 20px;
            box-shadow: 0 1px 3px rgba(0,0,0,0.1);
            transition: all 0.2s;
            cursor: pointer;
            border: 1px solid #e2e8f0;
        }

        .model-card:hover {
            box-shadow: 0 4px 12px rgba(0,0,0,0.15);
            transform: translateY(-2px);
        }

        .model-header {
            display: flex;
            justify-content: space-between;
            align-items: start;
            margin-bottom: 12px;
        }

        .model-name {
            font-size: 1.3em;
            font-weight: 700;
            color: #1a202c;
        }

        .model-family {
            font-size: 0.85em;
            color: #4a5568;
            font-weight: 600;
            background: #edf2f7;
            padding: 4px 10px;
            border-radius: 4px;
        }

        .model-type {
            display: inline-block;
            font-size: 0.8em;
            background: #718096;
            color: white;
            padding: 4px 10px;
            border-radius: 4px;
            margin-bottom: 10px;
        }

        .modalities {
            display: flex;
            flex-wrap: wrap;
            gap: 6px;
            margin-bottom: 12px;
        }

        .modality-badge {
            font-size: 0.75em;
            padding: 4px 8px;
            border-radius: 4px;
            background: #f7fafc;
            border: 1px solid #e2e8f0;
            color: #4a5568;
        }

        .model-description {
            font-size: 0.9em;
            color: #4a5568;
            line-height: 1.5;
        }

        .stats {
            background: white;
            border-radius: 8px;
            padding: 20px;
            margin-top: 20px;
            box-shadow: 0 1px 3px rgba(0,0,0,0.1);
        }

        .stats-grid {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(200px, 1fr));
            gap: 15px;
        }

        .stat-item {
            text-align: center;
            padding: 20px;
            background: #f7fafc;
            border-radius: 6px;
            border: 1px solid #e2e8f0;
        }

        .stat-number {
            font-size: 2em;
            font-weight: 700;
            display: block;
            color: #2d3748;
        }

        .stat-label {
            font-size: 0.9em;
            color: #718096;
            margin-top: 5px;
        }

        .modal {
            display: none;
            position: fixed;
            top: 0;
            left: 0;
            right: 0;
            bottom: 0;
            background: rgba(0,0,0,0.5);
            z-index: 1000;
            padding: 20px;
            overflow-y: auto;
        }

        .modal-content {
            background: white;
            max-width: 600px;
            margin: 50px auto;
            border-radius: 8px;
            padding: 30px;
            position: relative;
            box-shadow: 0 4px 24px rgba(0,0,0,0.2);
        }

        .close-btn {
            position: absolute;
            top: 15px;
            right: 15px;
            font-size: 1.5em;
            cursor: pointer;
            color: #718096;
            background: none;
            border: none;
        }

        .close-btn:hover {
            color: #2d3748;
        }

        .modal h2 {
            color: #1a202c;
            margin-bottom: 15px;
        }

        .modal-tags {
            display: flex;
            flex-wrap: wrap;
            gap: 8px;
            margin: 15px 0;
        }

        .no-results {
            text-align: center;
            padding: 40px;
            background: white;
            border-radius: 8px;
            color: #718096;
        }
    </style>
</head>
<body>
    <div class="container">
        <header>
            <h1>AI Model Explorer</h1>
            <p class="subtitle">Discover and compare AI models across categories, types, and capabilities</p>
        </header>

        <div class="tabs">
            <button class="tab active" onclick="switchTab('llm')">Language Models</button>
            <button class="tab" onclick="switchTab('diffusion')">Image Generation</button>
            <button class="tab" onclick="switchTab('audio')">Audio Models</button>
            <button class="tab" onclick="switchTab('video')">Video Models</button>
            <button class="tab" onclick="switchTab('multimodal')">Multimodal</button>
        </div>

        <div id="llm" class="tab-content active">
            <div class="controls">
                <div class="filter-group">
                    <label>Filter by Family:</label>
                    <div class="filter-buttons" id="llmFamilyFilters"></div>
                </div>
                <div class="filter-group">
                    <label>Filter by Type:</label>
                    <div class="filter-buttons" id="llmTypeFilters"></div>
                </div>
                <div class="filter-group">
                    <label>Filter by Capability:</label>
                    <div class="filter-buttons" id="llmModalityFilters"></div>
                </div>
            </div>
            <div class="models-grid" id="llmGrid"></div>
            <div class="stats">
                <h2 style="margin-bottom: 15px;">Overview Statistics</h2>
                <div class="stats-grid" id="llmStats"></div>
            </div>
        </div>

        <div id="diffusion" class="tab-content">
            <div class="controls">
                <div class="filter-group">
                    <label>Filter by Family:</label>
                    <div class="filter-buttons" id="diffusionFamilyFilters"></div>
                </div>
                <div class="filter-group">
                    <label>Filter by Type:</label>
                    <div class="filter-buttons" id="diffusionTypeFilters"></div>
                </div>
                <div class="filter-group">
                    <label>Filter by Capability:</label>
                    <div class="filter-buttons" id="diffusionModalityFilters"></div>
                </div>
            </div>
            <div class="models-grid" id="diffusionGrid"></div>
            <div class="stats">
                <h2 style="margin-bottom: 15px;">Overview Statistics</h2>
                <div class="stats-grid" id="diffusionStats"></div>
            </div>
        </div>

        <div id="audio" class="tab-content">
            <div class="controls">
                <div class="filter-group">
                    <label>Filter by Family:</label>
                    <div class="filter-buttons" id="audioFamilyFilters"></div>
                </div>
                <div class="filter-group">
                    <label>Filter by Type:</label>
                    <div class="filter-buttons" id="audioTypeFilters"></div>
                </div>
                <div class="filter-group">
                    <label>Filter by Capability:</label>
                    <div class="filter-buttons" id="audioModalityFilters"></div>
                </div>
            </div>
            <div class="models-grid" id="audioGrid"></div>
            <div class="stats">
                <h2 style="margin-bottom: 15px;">Overview Statistics</h2>
                <div class="stats-grid" id="audioStats"></div>
            </div>
        </div>

        <div id="video" class="tab-content">
            <div class="controls">
                <div class="filter-group">
                    <label>Filter by Family:</label>
                    <div class="filter-buttons" id="videoFamilyFilters"></div>
                </div>
                <div class="filter-group">
                    <label>Filter by Type:</label>
                    <div class="filter-buttons" id="videoTypeFilters"></div>
                </div>
                <div class="filter-group">
                    <label>Filter by Capability:</label>
                    <div class="filter-buttons" id="videoModalityFilters"></div>
                </div>
            </div>
            <div class="models-grid" id="videoGrid"></div>
            <div class="stats">
                <h2 style="margin-bottom: 15px;">Overview Statistics</h2>
                <div class="stats-grid" id="videoStats"></div>
            </div>
        </div>

        <div id="multimodal" class="tab-content">
            <div class="controls">
                <div class="filter-group">
                    <label>Filter by Family:</label>
                    <div class="filter-buttons" id="multimodalFamilyFilters"></div>
                </div>
                <div class="filter-group">
                    <label>Filter by Type:</label>
                    <div class="filter-buttons" id="multimodalTypeFilters"></div>
                </div>
                <div class="filter-group">
                    <label>Filter by Capability:</label>
                    <div class="filter-buttons" id="multimodalModalityFilters"></div>
                </div>
            </div>
            <div class="models-grid" id="multimodalGrid"></div>
            <div class="stats">
                <h2 style="margin-bottom: 15px;">Overview Statistics</h2>
                <div class="stats-grid" id="multimodalStats"></div>
            </div>
        </div>
    </div>

    <div class="modal" id="modal">
        <div class="modal-content">
            <button class="close-btn" onclick="closeModal()">×</button>
            <div id="modalBody"></div>
        </div>
    </div>

    <script>
        const modelData = {
            llm: [
                {
                    name: "GPT-4",
                    family: "OpenAI",
                    type: "Large Language Model",
                    modalities: ["Text", "Code", "Reasoning"],
                    description: "Advanced reasoning and problem-solving capabilities with strong performance across diverse tasks.",
                    details: "GPT-4 represents a significant advancement in language models with enhanced reasoning, factual accuracy, and the ability to handle complex instructions. It excels at tasks requiring nuanced understanding and multi-step reasoning."
                },
                {
                    name: "GPT-3.5",
                    family: "OpenAI",
                    type: "Large Language Model",
                    modalities: ["Text", "Code"],
                    description: "Fast and efficient text generation with strong conversational abilities.",
                    details: "GPT-3.5 offers a balance of performance and speed, making it ideal for chatbots, content generation, and general-purpose text tasks."
                },
                {
                    name: "Claude 4 Opus",
                    family: "Anthropic",
                    type: "Large Language Model",
                    modalities: ["Text", "Code", "Analysis", "Reasoning"],
                    description: "Highest intelligence and capability for complex analysis and creative tasks.",
                    details: "Claude 4 Opus excels at advanced reasoning, research, complex problem-solving, and creative writing with nuanced understanding of context and user intent."
                },
                {
                    name: "Claude 4.5 Sonnet",
                    family: "Anthropic",
                    type: "Large Language Model",
                    modalities: ["Text", "Code", "Analysis"],
                    description: "Balance of intelligence and speed for everyday tasks and coding.",
                    details: "Claude Sonnet 4.5 offers strong performance across diverse tasks with particular strength in coding, analysis, and multi-step reasoning."
                },
                {
                    name: "Gemini Ultra",
                    family: "Google",
                    type: "Large Language Model",
                    modalities: ["Text", "Code", "Reasoning", "Math"],
                    description: "Google's most capable language model with strong reasoning capabilities.",
                    details: "Gemini Ultra demonstrates state-of-the-art performance on complex reasoning tasks with particular strength in mathematical and scientific domains."
                },
                {
                    name: "Gemini Pro",
                    family: "Google",
                    type: "Large Language Model",
                    modalities: ["Text", "Code"],
                    description: "Efficient model for a wide range of tasks with good performance.",
                    details: "Gemini Pro provides strong performance across text generation tasks with good efficiency for production deployments."
                },
                {
                    name: "LLaMA 3",
                    family: "Meta",
                    type: "Large Language Model",
                    modalities: ["Text", "Code"],
                    description: "Open-source model with strong performance across benchmarks.",
                    details: "LLaMA 3 is Meta's flagship open-source model, offering competitive performance with excellent fine-tuning capabilities for custom applications."
                },
                {
                    name: "Mistral Large",
                    family: "Mistral AI",
                    type: "Large Language Model",
                    modalities: ["Text", "Code", "Multilingual"],
                    description: "High-performance multilingual model with strong reasoning capabilities.",
                    details: "Mistral Large excels at multilingual tasks, code generation, and reasoning with efficient architecture for cost-effective deployment."
                },
                {
                    name: "Mixtral 8x7B",
                    family: "Mistral AI",
                    type: "Mixture-of-Experts",
                    modalities: ["Text", "Code"],
                    description: "Mixture-of-experts model combining efficiency with strong performance.",
                    details: "Mixtral uses a sparse mixture-of-experts architecture, activating only relevant experts for each input, achieving excellent performance-to-cost ratio."
                },
                {
                    name: "PaLM 2",
                    family: "Google",
                    type: "Large Language Model",
                    modalities: ["Text", "Code", "Multilingual"],
                    description: "Multilingual and reasoning-focused model powering various Google products.",
                    details: "PaLM 2 demonstrates strong multilingual capabilities and advanced reasoning, integrated across Google's product ecosystem."
                }
            ],
            diffusion: [
                {
                    name: "DALL-E 3",
                    family: "OpenAI",
                    type: "Text-to-Image",
                    modalities: ["Text Input", "Image Output", "Prompt Following"],
                    description: "Advanced text-to-image generation with improved prompt following and detail.",
                    details: "DALL-E 3 generates highly detailed and accurate images from text descriptions, with better understanding of nuanced prompts and artistic styles. Integrated with ChatGPT for refined prompt engineering."
                },
                {
                    name: "Stable Diffusion XL",
                    family: "Stability AI",
                    type: "Text-to-Image",
                    modalities: ["Text Input", "Image Output", "Fine-tuning"],
                    description: "Open-source image generation model with high-quality outputs.",
                    details: "SDXL produces photorealistic images with improved composition and detail. Available as open-source for customization, fine-tuning, and commercial use."
                },
                {
                    name: "Stable Diffusion 3",
                    family: "Stability AI",
                    type: "Text-to-Image",
                    modalities: ["Text Input", "Image Output", "Multi-subject"],
                    description: "Latest generation with improved text rendering and multi-subject composition.",
                    details: "SD3 uses a new architecture for better text accuracy in images and handling complex scenes with multiple subjects and detailed compositions."
                },
                {
                    name: "Midjourney v6",
                    family: "Midjourney",
                    type: "Text-to-Image",
                    modalities: ["Text Input", "Image Output", "Artistic"],
                    description: "Artistic image generation with strong aesthetic quality and prompt understanding.",
                    details: "Midjourney v6 excels at creating visually striking, artistic images with improved prompt accuracy and detailed rendering capabilities."
                },
                {
                    name: "Imagen 2",
                    family: "Google",
                    type: "Text-to-Image",
                    modalities: ["Text Input", "Image Output", "Photorealistic"],
                    description: "Google's text-to-image model with strong photorealism.",
                    details: "Imagen 2 generates highly realistic images with accurate text rendering and strong adherence to prompts, integrated into Google products."
                },
                {
                    name: "ControlNet",
                    family: "Community",
                    type: "Image-to-Image",
                    modalities: ["Image Input", "Image Output", "Spatial Control"],
                    description: "Enables precise spatial control over image generation using reference images.",
                    details: "ControlNet adds conditional control to diffusion models, allowing users to guide generation with edge maps, depth maps, poses, and other structural inputs."
                },
                {
                    name: "Stable Video Diffusion",
                    family: "Stability AI",
                    type: "Image-to-Video",
                    modalities: ["Image Input", "Video Output"],
                    description: "Generates short video clips from static images.",
                    details: "SVD converts still images into short animated videos, useful for creating motion from single frames with temporal consistency."
                }
            ],
            audio: [
                {
                    name: "Whisper",
                    family: "OpenAI",
                    type: "Speech-to-Text",
                    modalities: ["Audio Input", "Text Output", "Multilingual"],
                    description: "Robust speech recognition supporting multiple languages and accents.",
                    details: "Whisper provides state-of-the-art speech transcription with strong performance across languages, accents, and noisy audio conditions. Available as open-source."
                },
                {
                    name: "ElevenLabs",
                    family: "ElevenLabs",
                    type: "Text-to-Speech",
                    modalities: ["Text Input", "Audio Output", "Voice Cloning"],
                    description: "High-quality text-to-speech with natural voices and voice cloning capabilities.",
                    details: "ElevenLabs generates highly realistic speech with emotional range, voice cloning from short samples, and support for multiple languages."
                },
                {
                    name: "Bark",
                    family: "Suno AI",
                    type: "Text-to-Audio",
                    modalities: ["Text Input", "Audio Output", "Music", "Sound Effects"],
                    description: "Generates speech, music, and sound effects from text prompts.",
                    details: "Bark is a versatile audio generation model that can create speech in multiple languages, music, background noise, and sound effects from text descriptions."
                },
                {
                    name: "MusicGen",
                    family: "Meta",
                    type: "Text-to-Music",
                    modalities: ["Text Input", "Audio Output", "Music"],
                    description: "Generates music from text descriptions and melodic inputs.",
                    details: "MusicGen creates high-quality music samples from text prompts, with support for melody conditioning and various musical styles and instruments."
                },
                {
                    name: "AudioCraft",
                    family: "Meta",
                    type: "Audio Generation",
                    modalities: ["Text Input", "Audio Output", "Sound Design"],
                    description: "Suite of models for music and audio generation.",
                    details: "AudioCraft includes MusicGen for music and AudioGen for sound effects, providing comprehensive audio generation capabilities for creative applications."
                },
                {
                    name: "Tortoise TTS",
                    family: "Community",
                    type: "Text-to-Speech",
                    modalities: ["Text Input", "Audio Output", "Voice Cloning"],
                    description: "Open-source high-quality text-to-speech with voice cloning.",
                    details: "Tortoise TTS generates extremely natural-sounding speech with the ability to clone voices from reference audio samples. Prioritizes quality over speed."
                }
            ],
            video: [
                {
                    name: "Sora",
                    family: "OpenAI",
                    type: "Text-to-Video",
                    modalities: ["Text Input", "Video Output", "Long Duration"],
                    description: "Advanced text-to-video generation with temporal consistency and realistic motion.",
                    details: "Sora can generate videos up to 60 seconds with complex scenes, multiple characters, and consistent physics. Shows understanding of how objects exist in physical space."
                },
                {
                    name: "Runway Gen-2",
                    family: "Runway",
                    type: "Text-to-Video",
                    modalities: ["Text Input", "Image Input", "Video Output"],
                    description: "Generates videos from text and image prompts with stylistic control.",
                    details: "Gen-2 creates short video clips with artistic control, supporting text-to-video, image-to-video, and video-to-video transformations for creative workflows."
                },
                {
                    name: "Pika",
                    family: "Pika Labs",
                    type: "Text-to-Video",
                    modalities: ["Text Input", "Video Output", "Editing"],
                    description: "Video generation with editing capabilities for modifying regions and extending clips.",
                    details: "Pika enables video creation and editing with the ability to modify specific regions, extend videos, and transform existing footage with AI."
                },
                {
                    name: "Stable Video Diffusion",
                    family: "Stability AI",
                    type: "Image-to-Video",
                    modalities: ["Image Input", "Video Output"],
                    description: "Generates short video animations from single images.",
                    details: "SVD creates video sequences from still images, adding motion and temporal dynamics while maintaining visual consistency throughout the animation."
                },
                {
                    name: "AnimateDiff",
                    family: "Community",
                    type: "Image-to-Video",
                    modalities: ["Image Input", "Video Output", "Motion Control"],
                    description: "Animates images with motion modules for Stable Diffusion.",
                    details: "AnimateDiff adds temporal layers to Stable Diffusion models, enabling animation of generated or real images with various motion patterns and controls."
                }
            ],
            multimodal: [
                {
                    name: "GPT-4V",
                    family: "OpenAI",
                    type: "Vision-Language",
                    modalities: ["Text", "Image", "Document Analysis"],
                    description: "GPT-4 with vision capabilities for understanding and analyzing images.",
                    details: "GPT-4V combines language understanding with visual processing, enabling tasks like image description, visual question answering, document analysis, and chart interpretation."
                },
                {
                    name: "Claude 4 Opus",
                    family: "Anthropic",
                    type: "Vision-Language",
                    modalities: ["Text", "Image", "Document", "Chart Analysis"],
                    description: "Multimodal understanding with advanced reasoning over visual and text content.",
                    details: "Claude 4 Opus processes images, documents, and charts alongside text, excelling at detailed visual analysis, document processing, and complex multimodal reasoning tasks."
                },
                {
                    name: "Gemini Ultra",
                    family: "Google",
                    type: "Natively Multimodal",
                    modalities: ["Text", "Image", "Audio", "Video"],
                    description: "Natively multimodal model processing multiple input types simultaneously.",
                    details: "Gemini Ultra is designed from the ground up for multimodal understanding, processing text, images, audio, and video in a unified architecture for cross-modal reasoning."
                },
                {
                    name: "LLaVA",
                    family: "Community",
                    type: "Vision-Language",
                    modalities: ["Text", "Image"],
                    description: "Open-source vision-language model for visual instruction following.",
                    details: "LLaVA (Large Language and Vision Assistant) enables visual understanding and instruction following, trained on visual instruction tuning data for diverse tasks."
                },
                {
                    name: "CLIP",
                    family: "OpenAI",
                    type: "Vision-Language",
                    modalities: ["Text", "Image", "Zero-shot Classification"],
                    description: "Connects text and images for zero-shot classification and retrieval.",
                    details: "CLIP learns visual concepts from natural language supervision, enabling zero-shot image classification, image-text matching, and semantic image search without task-specific training."
                },
                {
                    name: "Flamingo",
                    family: "DeepMind",
                    type: "Vision-Language",
                    modalities: ["Text", "Image", "Video", "Few-shot Learning"],
                    description: "Few-shot learning across vision and language tasks.",
                    details: "Flamingo handles interleaved text and visual inputs with strong few-shot learning capabilities, adapting to new visual tasks with minimal examples."
                },
                {
                    name: "ImageBind",
                    family: "Meta",
                    type: "Any-to-Any",
                    modalities: ["Text", "Image", "Audio", "Depth", "Thermal", "IMU"],
                    description: "Binds multiple modalities into a joint embedding space.",
                    details: "ImageBind creates a unified representation space for six modalities, enabling cross-modal retrieval and understanding without paired training data between all modality combinations."
                }
            ]
        };

        let activeFilters = {};
        let currentTab = 'llm';

        function initializeFilters(category) {
            activeFilters[category] = {
                family: new Set(),
                type: new Set(),
                modality: new Set()
            };
        }

        Object.keys(modelData).forEach(category => initializeFilters(category));

        function switchTab(tabName) {
            document.querySelectorAll('.tab').forEach(t => t.classList.remove('active'));
            document.querySelectorAll('.tab-content').forEach(c => c.classList.remove('active'));
            
            event.target.classList.add('active');
            document.getElementById(tabName).classList.add('active');
            
            currentTab = tabName;
            renderModels(tabName);
        }

        function getAllUnique(category, field) {
            if (field === 'modalities') {
                const all = new Set();
                modelData[category].forEach(m => m.modalities.forEach(mod => all.add(mod)));
                return Array.from(all).sort();
            }
            return [...new Set(modelData[category].map(m => m[field]))].sort();
        }

        function createFilterButtons(category) {
            const families = getAllUnique(category, 'family');
            const types = getAllUnique(category, 'type');
            const modalities = getAllUnique(category, 'modalities');

            const familyDiv = document.getElementById(`${category}FamilyFilters`);
            const typeDiv = document.getElementById(`${category}TypeFilters`);
            const modalityDiv = document.getElementById(`${category}ModalityFilters`);

            familyDiv.innerHTML = '';
            typeDiv.innerHTML = '';
            modalityDiv.innerHTML = '';

            families.forEach(family => {
                const btn = document.createElement('button');
                btn.className = 'filter-btn';
                btn.textContent = family;
                btn.onclick = () => toggleFilter(category, 'family', family, btn);
                familyDiv.appendChild(btn);
            });

            types.forEach(type => {
                const btn = document.createElement('button');
                btn.className = 'filter-btn';
                btn.textContent = type;
                btn.onclick = () => toggleFilter(category, 'type', type, btn);
                typeDiv.appendChild(btn);
            });

            modalities.forEach(modality => {
                const btn = document.createElement('button');
                btn.className = 'filter-btn';
                btn.textContent = modality;
                btn.onclick = () => toggleFilter(category, 'modality', modality, btn);
                modalityDiv.appendChild(btn);
            });
        }

        function toggleFilter(category, filterType, value, btn) {
            if (activeFilters[category][filterType].has(value)) {
                activeFilters[category][filterType].delete(value);
                btn.classList.remove('active');
            } else {
                activeFilters[category][filterType].add(value);
                btn.classList.add('active');
            }
            renderModels(category);
            updateStats(category);
        }

        function filterModels(category) {
            return modelData[category].filter(model => {
                if (activeFilters[category].family.size > 0 && !activeFilters[category].family.has(model.family)) {
                    return false;
                }
                if (activeFilters[category].type.size > 0 && !activeFilters[category].type.has(model.type)) {
                    return false;
                }
                if (activeFilters[category].modality.size > 0) {
                    const hasModality = model.modalities.some(m => activeFilters[category].modality.has(m));
                    if (!hasModality) return false;
                }
                return true;
            });
        }

        function renderModels(category) {
            const grid = document.getElementById(`${category}Grid`);
            const filtered = filterModels(category);

            if (filtered.length === 0) {
                grid.innerHTML = '<div class="no-results">No models match your filters. Try adjusting your selection.</div>';
                return;
            }

            grid.innerHTML = filtered.map(model => `
                <div class="model-card" onclick='showModal(${JSON.stringify(model).replace(/'/g, "&#39;")})'>
                    <div class="model-header">
                        <div class="model-name">${model.name}</div>
                        <div class="model-family">${model.family}</div>
                    </div>
                    <div class="model-type">${model.type}</div>
                    <div class="modalities">
                        ${model.modalities.map(m => `<span class="modality-badge">${m}</span>`).join('')}
                    </div>
                    <div class="model-description">${model.description}</div>
                </div>
            `).join('');
        }

        function showModal(model) {
            const modal = document.getElementById('modal');
            const modalBody = document.getElementById('modalBody');
            
            modalBody.innerHTML = `
                <h2>${model.name}</h2>
                <div class="modal-tags">
                    <span class="model-type">${model.type}</span>
                    <span class="model-family">${model.family}</span>
                </div>
                <div class="modalities" style="margin-bottom: 15px;">
                    ${model.modalities.map(m => `<span class="modality-badge">${m}</span>`).join('')}
                </div>
                <p style="line-height: 1.6; color: #4a5568;">${model.details}</p>
            `;
            
            modal.style.display = 'block';
        }

        function closeModal() {
            document.getElementById('modal').style.display = 'none';
        }

        function updateStats(category) {
            const filtered = filterModels(category);
            const statsGrid = document.getElementById(`${category}Stats`);
            
            const familyCount = new Set(filtered.map(m => m.family)).size;
            const typeCount = new Set(filtered.map(m => m.type)).size;
            const modalitySet = new Set();
            filtered.forEach(m => m.modalities.forEach(mod => modalitySet.add(mod)));
            
            statsGrid.innerHTML = `
                <div class="stat-item">
                    <span class="stat-number">${filtered.length}</span>
                    <span class="stat-label">Models</span>
                </div>
                <div class="stat-item">
                    <span class="stat-number">${familyCount}</span>
                    <span class="stat-label">Families</span>
                </div>
                <div class="stat-item">
                    <span class="stat-number">${typeCount}</span>
                    <span class="stat-label">Types</span>
                </div>
                <div class="stat-item">
                    <span class="stat-number">${modalitySet.size}</span>
                    <span class="stat-label">Capabilities</span>
                </div>
            `;
        }

        window.onclick = function(event) {
            const modal = document.getElementById('modal');
            if (event.target === modal) {
                closeModal();
            }
        }

        Object.keys(modelData).forEach(category => {
            createFilterButtons(category);
            renderModels(category);
            updateStats(category);
        });
    </script>
</body>
</html>